{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train_ = pd.read_csv(\"training_v2.csv\")\r\n",
    "predict_ = pd.read_csv(\"unlabeled.csv\")\r\n",
    "\r\n",
    "train_['label'] = 'train'\r\n",
    "predict_['label'] = 'test'\r\n",
    "\r\n",
    "train_.drop(['encounter_id', 'hospital_id', 'patient_id', 'icu_id', 'readmission_status'], inplace=True, axis=1)\r\n",
    "predict_.drop(['encounter_id', 'hospital_id', 'patient_id', 'icu_id', 'readmission_status', \r\n",
    "'hospital_death'], inplace=True, axis=1)\r\n",
    "\r\n",
    "print(train_.shape)\r\n",
    "print(predict_.shape)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train_[\"height\"] = np.where((train_.height.isna() & (train_.gender == 'F')), 160, train_[\"height\"])\r\n",
    "train_[\"height\"] = np.where((train_.height.isna() & (train_.gender == 'M')), 180, train_[\"height\"])\r\n",
    "train_[\"height\"] = np.where((train_.height.isna() & (train_.gender.isna())), 170, train_[\"height\"])\r\n",
    "train_[\"weight\"] = np.where((train_.height.isna() & (train_.gender == 'F')), 65, train_[\"weight\"])\r\n",
    "train_[\"weight\"] = np.where((train_.height.isna() & (train_.gender == 'M')), 82, train_[\"weight\"])\r\n",
    "train_[\"weight\"] = np.where((train_.height.isna() & (train_.gender.isna())), 74, train_[\"weight\"])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "predict_[\"height\"] = np.where((predict_.height.isna() & (predict_.gender == 'F')), 160, predict_[\"height\"])\r\n",
    "predict_[\"height\"] = np.where((predict_.height.isna() & (predict_.gender == 'M')), 180, predict_[\"height\"])\r\n",
    "predict_[\"height\"] = np.where((predict_.height.isna() & (predict_.gender.isna())), 170, predict_[\"height\"])\r\n",
    "predict_[\"weight\"] = np.where((predict_.height.isna() & (predict_.gender == 'F')), 65, predict_[\"weight\"])\r\n",
    "predict_[\"weight\"] = np.where((predict_.height.isna() & (predict_.gender == 'M')), 82, predict_[\"weight\"])\r\n",
    "predict_[\"weight\"] = np.where((predict_.height.isna() & (predict_.gender.isna())), 74, predict_[\"weight\"])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from matplotlib import pyplot as plt\r\n",
    "import seaborn as sns\r\n",
    "\r\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(16, 6))\r\n",
    "\r\n",
    "sns.kdeplot(train_[train_.gender == 'F'].weight, label='Female', color='salmon', ax=ax[0])\r\n",
    "sns.kdeplot(train_[train_.gender == 'M'].weight, label='Male', color='dodgerblue', ax=ax[0])\r\n",
    "ax[0].set_title('Weight [kg]', fontsize=14)\r\n",
    "\r\n",
    "sns.kdeplot(train_[train_.gender == 'F'].height, label='Female', color='salmon', ax=ax[1])\r\n",
    "sns.kdeplot(train_[train_.gender == 'M'].height, label='Male', color='dodgerblue', ax=ax[1])\r\n",
    "ax[1].set_title('Height [cm]', fontsize=14)\r\n",
    "\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "lst = train_.isna().sum() / len(train_)\r\n",
    "\r\n",
    "p = pd.DataFrame(lst)\r\n",
    "\r\n",
    "# When we reset the index, the old index is added as a column, and a new sequential index is used\r\n",
    "p.reset_index(inplace=True)\r\n",
    "\r\n",
    "p.columns = ['a', 'b']\r\n",
    "low_count = p[p['b'] > 0.4]\r\n",
    "\r\n",
    "todelete = low_count['a'].values\r\n",
    "\r\n",
    "train_.drop(todelete, axis=1, inplace=True)\r\n",
    "predict_.drop(todelete, axis=1, inplace=True)\r\n",
    "\r\n",
    "train_.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train_.dropna(thresh=54, inplace=True)\r\n",
    "train_.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train_test = pd.concat([train_, predict_], keys=['x', 'y'])\r\n",
    "train_test.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dictionary_ = pd.read_csv(\"WiDS Datathon 2020 Dictionary.csv\")\r\n",
    "print(dictionary_.shape)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "integer_cols = []\r\n",
    "binary_cols = []\r\n",
    "numeric_cols = []\r\n",
    "string_cols = []\r\n",
    "\r\n",
    "for i in range(dictionary_.shape[0]):\r\n",
    "    if dictionary_.loc[i, 'Data Type'] == 'integer':\r\n",
    "        integer_cols.append(dictionary_.loc[i, 'Variable Name'])\r\n",
    "\r\n",
    "    if dictionary_.loc[i, 'Data Type'] == 'binary':\r\n",
    "        binary_cols.append(dictionary_.loc[i, 'Variable Name'])\r\n",
    "\r\n",
    "    if dictionary_.loc[i, 'Data Type'] == 'numeric':\r\n",
    "        numeric_cols.append(dictionary_.loc[i, 'Variable Name'])\r\n",
    "\r\n",
    "    if dictionary_.loc[i, 'Data Type'] == 'string':\r\n",
    "        string_cols.append(dictionary_.loc[i, 'Variable Name'])\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for col_name in numeric_cols:\r\n",
    "    if col_name in train_test.columns.to_list():\r\n",
    "        train_test[col_name] = train_test.groupby(['ethnicity', 'gender'], sort=False)[col_name].apply(lambda x: \r\n",
    "        x.fillna(x.mean()))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.impute import SimpleImputer\r\n",
    "\r\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\r\n",
    "train_test = imputer.fit_transform(train_test) \r\n",
    "\r\n",
    "train_test = pd.DataFrame(train_test, columns=train_.columns)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\r\n",
    "\r\n",
    "enc = OrdinalEncoder()\r\n",
    "\r\n",
    "for col_name in string_cols:\r\n",
    "    if col_name in train_test.columns.to_list():\r\n",
    "        train_test[col_name] = enc.fit_transform(train_test[[col_name]])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_bmi_category(bmi):\r\n",
    "    if bmi != bmi:  # NaN\r\n",
    "        return np.nan\r\n",
    "    elif bmi < 18.5:  # Underweight\r\n",
    "        return 'Underweight'\r\n",
    "    elif bmi < 25:  # Healthy weight\r\n",
    "        return 'Healthy weight'\r\n",
    "    elif bmi < 30:  # Overweight\r\n",
    "        return 'Overweight'\r\n",
    "    else:  # Obese\r\n",
    "        return 'Obese'    \r\n",
    "    \r\n",
    "train_test[\"bmi_cat\"] = train_test[\"bmi\"].apply(get_bmi_category)\r\n",
    "\r\n",
    "# value_counts() function returns a Series containing counts of unique values. \r\n",
    "# The resulting object will be in descending order so that the first element is the most frequently-occurring element.\r\n",
    "train_test[\"bmi_cat\"] = train_test[\"bmi_cat\"].fillna(train_test[\"bmi_cat\"].value_counts().index[0])\r\n",
    "\r\n",
    "def get_blood_pressure_category(sysbp, diasbp):\r\n",
    "    if ((sysbp < 90) & (diasbp < 60)):\r\n",
    "        return 1  # Low blood pressure\r\n",
    "    elif ((sysbp < 120) & (diasbp < 80)):\r\n",
    "        return 2  # Normal\r\n",
    "    elif ((sysbp < 140) & (diasbp < 90)):\r\n",
    "        return 3  # Pre-Hypertension\r\n",
    "    elif ((sysbp < 160) & (diasbp < 100)):\r\n",
    "        return 4  # Stage 1 Hypertension\r\n",
    "    else:\r\n",
    "        return 5  # Stage 2 Hypertension\r\n",
    "\r\n",
    "train_test['bp_cat'] = train_test[['d1_sysbp_max', 'd1_diasbp_max']].apply(\r\n",
    "    lambda x: get_blood_pressure_category(x.d1_sysbp_max, x.d1_diasbp_max), axis=1)\r\n",
    "\r\n",
    "train_test[\"bp_cat\"] = train_test[\"bp_cat\"].fillna(train_test[\"bp_cat\"].value_counts().index[0])\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# separate train and test\r\n",
    "train = train_test[train_test['label'] == \"train\"]\r\n",
    "predict = train_test[train_test['label'] == 'test']\r\n",
    "\r\n",
    "train.reset_index(inplace=True)\r\n",
    "train.drop(['label'], inplace=True, axis=1)\r\n",
    "\r\n",
    "predict.reset_index(inplace=True)\r\n",
    "predict.drop(['label'], inplace=True, axis=1)\r\n",
    "\r\n",
    "train = train.astype('float64')\r\n",
    "predict = predict.astype('float64')\r\n",
    "\r\n",
    "print(train.shape)\r\n",
    "print(predict.shape)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "num_feature = []\r\n",
    "\r\n",
    "for col_name in numeric_cols:\r\n",
    "    if col_name in train_test.columns.to_list():\r\n",
    "        num_feature.append(col_name)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create correlation matrix\r\n",
    "corr_matrix = train[num_feature].corr().abs()\r\n",
    "\r\n",
    "# Select upper triangle of correlation matrix\r\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\r\n",
    "\r\n",
    "# Find index of feature columns with correlation greater than 0.8\r\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.8)]\r\n",
    "\r\n",
    "train.drop(to_drop, inplace=True, axis=1)\r\n",
    "predict.drop(to_drop, inplace=True, axis=1)\r\n",
    "\r\n",
    "print(train.shape)\r\n",
    "print(predict.shape)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.decomposition import PCA\r\n",
    "pca = PCA(n_components=2)\r\n",
    "components = pca.fit_transform(train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import plotly.express as px\r\n",
    "\r\n",
    "fig = px.scatter(components, x=0, y=1, color=train['hospital_death'], width=1000, height=1000)\r\n",
    "fig.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.ensemble import IsolationForest\r\n",
    "\r\n",
    "iso = IsolationForest(contamination=0.5)\r\n",
    "yhat = iso.fit_predict(train)\r\n",
    "\r\n",
    "# select all rows that are not outliers\r\n",
    "mask = yhat != -1\r\n",
    "len(mask)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.covariance import EllipticEnvelope\r\n",
    "\r\n",
    "ee = EllipticEnvelope(contamination=0.5)\r\n",
    "yhat = ee.fit_predict(train)\r\n",
    "\r\n",
    "mask = yhat != -1\r\n",
    "len(mask)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train['hospital_death'].value_counts() / len(train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "y_train = train['hospital_death']\r\n",
    "\r\n",
    "train.drop(['hospital_death'], inplace=True, axis=1)\r\n",
    "\r\n",
    "cat_feature = []\r\n",
    "\r\n",
    "for col_name in train.columns.to_list():\r\n",
    "    if col_name not in numeric_cols:\r\n",
    "        cat_feature.append(col_name)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from imblearn.over_sampling import SMOTENC\r\n",
    "\r\n",
    "sm = SMOTENC(categorical_features=cat_feature)\r\n",
    "train_res, y_res = sm.fit_resample(train, y_train)\r\n",
    "\r\n",
    "y_train.value_counts() / len(train)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit"
  },
  "interpreter": {
   "hash": "6d47ee5640fc503c71f4bb20d34a99a4db90cdbb2bf7627af55566e1cfb8cabe"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}